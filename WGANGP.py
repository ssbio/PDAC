import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import torch
import torch.optim as optim
from torch import nn
from torch.utils.data import DataLoader
from MyDataTransforms import GeneExpressionDataset
from optparse import OptionParser
import matplotlib.pyplot as plt
import os
import numpy as np

# Specify save directory
save_directory = 'WGAN_Results_IncludeNonDuctalSample_2000_epoch_Jul17/'

# Create the directory if it doesn't exist
if not os.path.exists(save_directory):
    os.makedirs(save_directory)

parser = OptionParser()
parser.add_option("-f", dest = "fold", default = "", help = "Welches Fold wird benutzt")
options, args = parser.parse_args()

label = 0               # class for which the data is to be augmented
method = 'WGAN-GP'      # augmentation method
#f = int(options.fold)   # fold of cross validation
f = 4
augFactor = 35           # augmentation factor 

ngpu = 1        		# number of gpus
workers = 38     		# number of data loading workers
z_dim = 100     		# size of the latent vector z 
batchSize = 2   		# batch size
niter = 2000   		# number of epochs to train for
critic_iterations = 5	# number of critic iterations before generator trains
learning_rate = 1e-4    # learning rate
lambda_gp = 10          # 'weight' of the gradient penalty
scaler = MinMaxScaler(feature_range=(-1, 1))



################################################################
###################### LOAD ORIGINAL DATA ######################
################################################################

# Load file including training and test data for the specific k-fold split 
# Besides gene expression values data set has to contain information about 
# the subset type ('train' or 'test') as well as the labels of the samples (0 or 1)
# DF = pd.read_csv('your_file_directory/train_test_split_fold{}.csv'.format(f), index_col=0)

df1 = pd.read_excel('/work/ssbio/trazmpour2/iMAT_Model_5/01-Patient&Healthy_Gene_Expression_DBs/Final_healthy_with_genes.xlsx', header=0, index_col=0)
# Create a new row with zero values and the index 'labels'
labels_row = pd.DataFrame([0] * len(df1.columns), index=df1.columns).T
labels_row.index = ['label']

# Insert the new row into the DataFrame
df2 = pd.concat([labels_row, df1])
DF = df2.T
DF.insert(0, 'subset', ['train'] * len(DF))

# only include training data from specified class (label)
gandata = DF[(DF.subset == 'train') & (DF.label == label)]

# select expression values
genes = gandata.select_dtypes('float').columns
genes = genes.drop('label')
X_dim = len(genes)

print('Generate new data for label {} ; train for {} epochs'.format(gandata.label.unique().item(), niter))



###################################################
###################### MODEL ######################
###################################################

class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            nn.Linear(z_dim, 250, bias=True),
            nn.LeakyReLU(0.2,inplace=True),
            nn.Linear(250, 500, bias=True),
            nn.LeakyReLU(0.2,inplace=True),
            nn.Linear(500, 1000, bias=True),
            nn.LeakyReLU(0.2,inplace=True),
            nn.Linear(1000, X_dim, bias=True),
            nn.Tanh()
        )
    def forward(self, input):
        output = self.main(input)
        return output


class Critic(nn.Module):
    def __init__(self):
        super(Critic, self).__init__()
        self.main = nn.Sequential(
            nn.Linear(X_dim, 1000),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(1000, 500),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(500, 250),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(250, 1),
        )
    def forward(self, input):
        output = self.main(input)
        return output.squeeze(1)


def gradient_penalty(critic, real, fake):
    BATCHSIZE, GENES = real.shape
    epsilon = torch.rand((BATCHSIZE, 1)).repeat(1, GENES).cuda() 	
    interpolated_arrays = real * epsilon + fake * (1 - epsilon)
    mixed_scores = critic(interpolated_arrays) 				        
    gradient = torch.autograd.grad(     				            
        inputs = interpolated_arrays, 
        outputs = mixed_scores, 
        grad_outputs = torch.ones_like(mixed_scores), 
        create_graph = True, 
        retain_graph = True
    )[0]
    gradient = gradient.view(gradient.shape[0], -1) 			
    gradient_norm = gradient.norm(2, dim = 1)
    gradient_penalty = torch.mean((gradient_norm - 1)**2)
    return gradient_penalty
    

def weights_init(m):
    classname = m.__class__.__name__
    if isinstance(m, nn.Linear):
        nn.init.normal_(m.weight, 0.0, 0.02)
      
generator = Generator().cuda()
generator.apply(weights_init)
       
critic = Critic().cuda()
critic.apply(weights_init)

optimizerC = optim.Adam(critic.parameters(), lr=learning_rate, betas = (0.0, 0.9))
optimizerG = optim.Adam(generator.parameters(), lr=learning_rate, betas = (0.0, 0.9))



################################################################################
###################### TRAINING / DATA GENERATION - COVID ######################
################################################################################

# Scale values to range (-1, 1)
scaler.fit(gandata[genes])
gandata_sc = scaler.transform(gandata[genes])

# Prepare data for later saving
gandata_sc = pd.DataFrame(gandata_sc, index = gandata.index, columns = genes)
gandata_sc.insert(0, 'label', gandata.label)
# gandata_sc.insert(0, 'id', gandata.id)
gandata_sc.insert(0, 'subset', gandata.subset)

# Transfer the dataset into a specific structure that can be used by the pytorch dataloader for training
dataset = GeneExpressionDataset(gandata_sc, genes, True)

# Create pytorch DataLoader object
dataloader = DataLoader(dataset, batch_size = 2, shuffle = True, num_workers = 38)

# Specify number of samples that should be simulated
nnew = len(gandata)*augFactor

# create matrix containing nnew rows times z_dim columns
fixed_noise = torch.randn(nnew, z_dim).cuda()



def plot_history(g_hist, d_total_hist, fig_name):

 plt.figure(figsize=(8, 6))
 plt.plot(d_total_hist, label='Discriminator')
 plt.plot(g_hist, label='Generator')
 plt.legend()
 plt.xlabel('Epoch')
 plt.ylabel('Loss')
 plt.show()
 plt.savefig(os.path.join(save_directory, fig_name), dpi=600)
 print(f"Plot saved at: {os.path.abspath(save_directory)}")
 plt.close()


def plot_history_2(d_real_hist, d_fake_hist, fig_name):
 plt.figure(figsize=(8, 6))
 plt.plot(d_real_hist, label='Discriminator-real')
 plt.plot(d_fake_hist, label='Discriminator-synthetic')
 plt.legend()
 plt.xlabel('Epoch')
 plt.ylabel('Loss')
 plt.show()
 plt.savefig(os.path.join(save_directory, fig_name), dpi=600)
 print(f"Plot saved at: {os.path.abspath(save_directory)}")
 plt.close()

def plot_history_3(g_hist, d_total_hist, d_real_hist, d_fake_hist, fig_name):
 plt.figure(figsize=(8, 6))
 plt.plot(d_total_hist, label='Discriminator-total')
 plt.plot(g_hist, label='Generator')
 plt.plot(d_real_hist, label='Discriminator-real')
 plt.plot(d_fake_hist, label='Discriminator-synthetic')
 plt.legend()
 plt.xlabel('Epoch')
 plt.ylabel('Loss')
 plt.show()
 plt.savefig(os.path.join(save_directory, fig_name), dpi=600)
 print(f"Plot saved at: {os.path.abspath(save_directory)}")
 plt.close()

# Training of generator and critic networks

generator.train()
critic.train()

g_hist, d_real_hist, d_fake_hist, d_total_hist = [], [], [], []
g_hist_epoch, d_real_hist_epoch, d_fake_hist_epoch, d_total_hist_epoch = [], [], [], []
file_path = os.path.join(save_directory, 'Loss_over_Epochs.txt')
with open(file_path, 'w') as file:
	for epoch in range(niter):
		for i, data in enumerate(dataloader, 0):
			real_cpu = data[0].cuda()  
			for _ in range(critic_iterations):
				noise = torch.randn(batchSize, z_dim).cuda()
				fake = generator(noise) 
				critic_real = critic(real_cpu).reshape(-1)
				critic_fake = critic(fake).reshape(-1)
				gp = gradient_penalty(critic, real_cpu, fake)
				loss_critic = (-(torch.mean(critic_real) - torch.mean(critic_fake)) + lambda_gp * gp) # original + lambda * gradient penalty             
				# - (torch.mean ...): RMSprop is meant to minimize things, so just take negative (maximizing is the same as minimizing the negative)             
				critic.zero_grad()
				loss_critic.backward(retain_graph = True)
				optimizerC.step()
			output = critic(fake).reshape(-1)
			loss_gen = -torch.mean(output)
			generator.zero_grad()
			loss_gen.backward()
			optimizerG.step()
			print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f Loss_critic_real: %.4f Loss_critic_fake: %.4f' % (epoch, niter, i, len(dataloader), loss_critic, loss_gen, torch.mean(critic_real), torch.mean(critic_fake)))
			print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f Loss_critic_real: %.4f Loss_critic_fake: %.4f' % (epoch, niter, i, len(dataloader), loss_critic, loss_gen, torch.mean(critic_real), torch.mean(critic_fake)), file=file)
			
			#d_real_acc = torch.mean((critic_real > 0).float())
			#d_fake_acc = torch.mean((critic_fake < 0).float())
			#d_real_acc_hist.append(d_real_acc.item())
			#d_fake_acc_hist.append(d_fake_acc.item())

			g_hist.append(loss_gen.detach().cpu())
			d_real_hist.append(torch.mean(critic_real.detach().cpu()))
			d_fake_hist.append(torch.mean(critic_fake.detach().cpu()))
			d_total_hist.append(loss_critic.detach().cpu())
			
		g_hist_epoch.append(loss_gen.detach().cpu())
		d_real_hist_epoch.append(torch.mean(critic_real.detach().cpu()))
		d_fake_hist_epoch.append(torch.mean(critic_fake.detach().cpu()))
		d_total_hist_epoch.append(loss_critic.detach().cpu())
			
						
#plot_history(d_real_hist, d_fake_hist, d_total_hist, g_hist)
plot_history(g_hist, d_total_hist, fig_name = 'D_G_Loss')
plot_history(g_hist_epoch, d_total_hist_epoch, fig_name = 'Epoch_D_G_Loss')
plot_history_2(d_real_hist, d_fake_hist, fig_name = 'D_real_fake_Loss')
plot_history_2(d_real_hist_epoch, d_fake_hist_epoch, fig_name = 'Epoch_D_real_fake_Loss')
plot_history_3(g_hist, d_total_hist, d_real_hist, d_fake_hist, fig_name = 'D_G_real_fake_Loss')
plot_history_3(g_hist_epoch, d_total_hist_epoch, d_real_hist_epoch, d_fake_hist_epoch, fig_name = 'Epoch_D_G_real_fake_Loss')


# Saving Generator
# After training the generator
torch.save(generator.state_dict(), os.path.join(save_directory, 'IncludeGenerator.pth'))

# Code for loading the Generator for future:
# Load the saved generator
# first need to define Generator architecture
###  loaded_generator = Generator().cuda()  # Create a new instance of the Generator model 
# now you load the previously trained generator into the defined architectur:
###  loaded_generator.load_state_dict(torch.load(os.path.join(save_directory, 'IncludeGenerator.pth'))) 
###  loaded_generator.eval()  # Set the generator to evaluation mode

# Use the loaded generator for inference or other tasks
# ...


# generate artificial samples
with torch.no_grad():
	fakes = generator(fixed_noise).detach().cpu()

# re-transform scaled values
gen_np = fakes.numpy()
gen_np = scaler.inverse_transform(gen_np)

# save generated samples in dataframe
gen_df = pd.DataFrame(gen_np)
gen_df.columns = genes

# insert info columns for later analyses
idxnames = ['a{}_label{}'.format(i+1, label) for i in range(nnew)]
gen_df.insert(0, 'label', [label]*nnew)
gen_df.insert(0, 'id', idxnames)
gen_df.insert(0, 'subset', ['train']*nnew)

# append generated samples to original samples and save as csv file
columns = ['subset','label']+genes.tolist()
# aug_df = DF[(DF.label == label)][columns].append(gen_df[columns])
aug_df = pd.concat([DF[DF.label == label][columns], gen_df[columns]])
# aug_df.to_csv('{}_{}iterations_SubsetLabel{}_5times_augmented_train_test_fold{}.csv'.format(method, niter, label, f), index=False)
aug_df = aug_df.drop(aug_df.index[0:len(DF)])

# Check if there is any negative data in the synthetic data generated by the model

(aug_df.select_dtypes(include=['int','float']) < 0).any().any()


#df2=DF.append(aug_df)
df2 = pd.concat([DF, aug_df])

df3=df2.T

file_path = save_directory + 'GeneExpress.csv'

# Save the DataFrame to the specified file path
df3.to_csv(file_path, index=False)

